# Logstash Pipeline Configuration for Enterprise Security Platform
# Processes security logs from multiple sources

input {
  # Suricata EVE JSON logs
  beats {
    port => 5044
    type => "suricata"
  }
  
  # Istio/Envoy access logs
  beats {
    port => 5045
    type => "istio"
  }
  
  # pfSense firewall logs
  syslog {
    port => 5514
    type => "pfsense"
  }
  
  # Application logs
  beats {
    port => 5046
    type => "application"
  }
  
  # Windows Event Logs
  beats {
    port => 5047
    type => "winlogbeat"
  }
  
  # Syslog from various sources
  syslog {
    port => 5515
    type => "syslog"
  }
  
  # HTTP webhook for real-time alerts
  http {
    port => 8080
    type => "webhook"
  }
}

filter {
  # Common fields for all logs
  mutate {
    add_field => { "[@metadata][pipeline]" => "%{type}" }
    add_field => { "ingestion_timestamp" => "%{@timestamp}" }
  }
  
  # Suricata log processing
  if [type] == "suricata" {
    if [message] =~ /^{.*}$/ {
      json {
        source => "message"
      }
      
      # Parse timestamp
      date {
        match => [ "timestamp", "ISO8601" ]
      }
      
      # Extract and enrich alert data
      if [event_type] == "alert" {
        mutate {
          add_field => { "security_event_type" => "ids_alert" }
          add_field => { "severity_numeric" => "%{[alert][severity]}" }
        }
        
        # Map severity to text
        if [alert][severity] == 1 {
          mutate { add_field => { "severity_text" => "low" } }
        } else if [alert][severity] == 2 {
          mutate { add_field => { "severity_text" => "medium" } }
        } else if [alert][severity] == 3 {
          mutate { add_field => { "severity_text" => "high" } }
        } else if [alert][severity] == 4 {
          mutate { add_field => { "severity_text" => "critical" } }
        }
        
        # GeoIP enrichment
        geoip {
          source => "src_ip"
          target => "src_geoip"
        }
        
        geoip {
          source => "dest_ip"
          target => "dest_geoip"
        }
        
        # Threat intelligence enrichment
        translate {
          field => "src_ip"
          destination => "src_threat_intel"
          dictionary_path => "/etc/logstash/threat_intel/malicious_ips.yml"
          fallback => "clean"
        }
        
        # MITRE ATT&CK mapping
        if [alert][signature] =~ /(?i)sql.injection/ {
          mutate { add_field => { "mitre_technique" => "T1190" } }
          mutate { add_field => { "mitre_tactic" => "Initial Access" } }
        }
        
        if [alert][signature] =~ /(?i)brute.force/ {
          mutate { add_field => { "mitre_technique" => "T1110" } }
          mutate { add_field => { "mitre_tactic" => "Credential Access" } }
        }
        
        if [alert][signature] =~ /(?i)lateral.movement/ {
          mutate { add_field => { "mitre_technique" => "T1021" } }
          mutate { add_field => { "mitre_tactic" => "Lateral Movement" } }
        }
        
        # Calculate risk score
        ruby {
          code => "
            base_score = event.get('[alert][severity]').to_i * 20
            
            # Increase score for external sources
            if event.get('src_geoip') && event.get('src_geoip')['country_code2'] != 'US'
              base_score += 10
            end
            
            # Increase score for known bad IPs
            if event.get('src_threat_intel') == 'malicious'
              base_score += 30
            end
            
            # Increase score for critical services
            dest_port = event.get('dest_port').to_i
            if [22, 3389, 445, 1433, 3306].include?(dest_port)
              base_score += 15
            end
            
            event.set('risk_score', [base_score, 100].min)
          "
        }
      }
      
      # Process flow events
      if [event_type] == "flow" {
        mutate {
          add_field => { "security_event_type" => "network_flow" }
        }
        
        # Calculate flow duration
        if [flow][start] and [flow][end] {
          ruby {
            code => "
              start_time = Time.parse(event.get('[flow][start]'))
              end_time = Time.parse(event.get('[flow][end]'))
              duration = end_time - start_time
              event.set('flow_duration_seconds', duration)
            "
          }
        }
      }
    }
  }
  
  # Istio/Envoy log processing
  if [type] == "istio" {
    grok {
      match => { 
        "message" => '\[%{TIMESTAMP_ISO8601:timestamp}\] "%{WORD:method} %{URIPATH:path}(?:%{URIPARAM:params})? HTTP/%{NUMBER:http_version}" %{NUMBER:response_code} %{NUMBER:response_flags} %{NUMBER:bytes_received} %{NUMBER:bytes_sent} %{NUMBER:duration} %{NUMBER:upstream_service_time} "%{DATA:x_forwarded_for}" "%{DATA:user_agent}" "%{DATA:request_id}" "%{DATA:authority}" "%{DATA:upstream_host}"'
      }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    mutate {
      add_field => { "security_event_type" => "proxy_access" }
      convert => { "response_code" => "integer" }
      convert => { "bytes_received" => "integer" }
      convert => { "bytes_sent" => "integer" }
      convert => { "duration" => "integer" }
    }
    
    # Detect suspicious patterns
    if [response_code] >= 400 {
      mutate { add_field => { "suspicious_activity" => "http_error" } }
    }
    
    if [user_agent] =~ /(?i)(bot|crawler|scanner|sqlmap|nikto)/ {
      mutate { add_field => { "suspicious_activity" => "suspicious_user_agent" } }
    }
    
    if [path] =~ /(?i)(union|select|insert|delete|drop|script|javascript)/ {
      mutate { add_field => { "suspicious_activity" => "injection_attempt" } }
    }
  }
  
  # pfSense firewall log processing
  if [type] == "pfsense" {
    grok {
      match => { 
        "message" => "%{SYSLOGTIMESTAMP:timestamp} %{WORD:hostname} %{WORD:process}: %{GREEDYDATA:pf_message}"
      }
    }
    
    if [pf_message] =~ /^<\d+>/ {
      grok {
        match => { 
          "pf_message" => "<%{NUMBER:priority}>%{GREEDYDATA:pf_content}"
        }
      }
      
      # Parse firewall rule logs
      if [pf_content] =~ /filterlog/ {
        grok {
          match => { 
            "pf_content" => "filterlog: %{NUMBER:rule_number},%{DATA:sub_rule},%{DATA:anchor},%{DATA:tracker},%{WORD:interface},%{WORD:reason},%{WORD:action},%{WORD:direction},%{NUMBER:ip_version},%{GREEDYDATA:packet_info}"
          }
        }
        
        mutate {
          add_field => { "security_event_type" => "firewall_log" }
        }
        
        # Parse packet information based on protocol
        if [packet_info] {
          grok {
            match => { 
              "packet_info" => "%{IP:src_ip},%{IP:dest_ip},%{WORD:protocol},%{NUMBER:src_port},%{NUMBER:dest_port},%{GREEDYDATA:additional_info}"
            }
          }
        }
        
        # GeoIP for firewall logs
        if [src_ip] {
          geoip {
            source => "src_ip"
            target => "src_geoip"
          }
        }
      }
    }
  }
  
  # Windows Event Log processing
  if [type] == "winlogbeat" {
    mutate {
      add_field => { "security_event_type" => "windows_event" }
    }
    
    # Process security events
    if [winlog][event_id] == 4625 {
      mutate { add_field => { "event_category" => "failed_logon" } }
    }
    
    if [winlog][event_id] == 4624 {
      mutate { add_field => { "event_category" => "successful_logon" } }
    }
    
    if [winlog][event_id] == 4648 {
      mutate { add_field => { "event_category" => "explicit_logon" } }
    }
    
    if [winlog][event_id] == 4720 {
      mutate { add_field => { "event_category" => "user_account_created" } }
    }
  }
  
  # Common enrichment for all logs
  # Add network segment information
  cidr {
    address => [ "%{src_ip}" ]
    network => [ "10.0.0.0/8" ]
    add_field => { "src_network_segment" => "internal" }
  }
  
  cidr {
    address => [ "%{src_ip}" ]
    network => [ "172.16.0.0/12" ]
    add_field => { "src_network_segment" => "internal" }
  }
  
  cidr {
    address => [ "%{src_ip}" ]
    network => [ "192.168.0.0/16" ]
    add_field => { "src_network_segment" => "internal" }
  }
  
  if ![src_network_segment] {
    mutate { add_field => { "src_network_segment" => "external" } }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => [ "message", "host", "agent", "ecs", "input", "log" ]
  }
}

output {
  # Send to Elasticsearch with dynamic index names
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    
    # Dynamic index based on log type and date
    index => "security-%{type}-%{+YYYY.MM.dd}"
    
    # Use document type for routing
    document_type => "_doc"
    
    # Template management
    manage_template => true
    template_name => "security-logs"
    template_pattern => "security-*"
    template => "/etc/logstash/templates/security-template.json"
    template_overwrite => true
  }
  
  # Send high-priority alerts to separate index
  if [severity_text] == "critical" or [severity_text] == "high" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      user => "elastic"
      password => "${ELASTIC_PASSWORD}"
      index => "security-alerts-high-priority-%{+YYYY.MM.dd}"
    }
  }
  
  # Send to Kafka for real-time processing
  kafka {
    topic_id => "security-events"
    bootstrap_servers => "kafka:9092"
    codec => json
  }
  
  # Debug output (remove in production)
  if [type] == "debug" {
    stdout {
      codec => rubydebug
    }
  }
}
